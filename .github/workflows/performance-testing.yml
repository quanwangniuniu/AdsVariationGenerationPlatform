name: Performance Testing

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests weekly on Mondays at 4 AM UTC
    - cron: '0 4 * * 1'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - load
          - stress
          - endurance
          - spike

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Load testing
  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'load' || github.event_name == 'schedule' || github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install performance testing tools
        run: |
          pip install locust
          pip install requests

      - name: Create load test script
        run: |
          cat > load_test.py << 'EOF'
          from locust import HttpUser, task, between
          import random
          
          class WebsiteUser(HttpUser):
              wait_time = between(1, 3)
              
              def on_start(self):
                  """Called when a user starts"""
                  self.login()
              
              def login(self):
                  """Simulate user login"""
                  response = self.client.post("/api/auth/login/", json={
                      "username": "testuser",
                      "password": "testpass"
                  })
                  if response.status_code == 200:
                      self.token = response.json().get("token")
                      self.client.headers.update({"Authorization": f"Token {self.token}"})
              
              @task(3)
              def view_homepage(self):
                  """View homepage"""
                  self.client.get("/")
              
              @task(2)
              def view_api(self):
                  """View API endpoints"""
                  self.client.get("/api/")
              
              @task(2)
              def view_workspaces(self):
                  """View workspaces"""
                  self.client.get("/api/workspaces/")
              
              @task(2)
              def view_campaigns(self):
                  """View campaigns"""
                  self.client.get("/api/campaigns/")
              
              @task(1)
              def create_campaign(self):
                  """Create a new campaign"""
                  self.client.post("/api/campaigns/", json={
                      "name": f"Test Campaign {random.randint(1, 1000)}",
                      "description": "Performance test campaign",
                      "budget": 1000.00,
                      "start_date": "2024-01-01T00:00:00Z",
                      "end_date": "2024-12-31T23:59:59Z"
                  })
              
              @task(1)
              def upload_asset(self):
                  """Upload an asset"""
                  # Simulate file upload
                  files = {"file": ("test.txt", "test content", "text/plain")}
                  self.client.post("/api/workspaces/1/upload/", files=files)
          EOF

      - name: Run load test
        run: |
          # Start the application (this would be replaced with actual deployment)
          echo "Starting application for load testing..."
          
          # Run load test
          locust -f load_test.py --headless -u 50 -r 5 -t 300s --html load_test_report.html || true

      - name: Upload load test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: load-test-report
          path: load_test_report.html

  # Stress testing
  stress-testing:
    name: Stress Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'stress' || github.event_name == 'schedule'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install performance testing tools
        run: |
          pip install locust
          pip install requests

      - name: Create stress test script
        run: |
          cat > stress_test.py << 'EOF'
          from locust import HttpUser, task, between
          import random
          
          class StressTestUser(HttpUser):
              wait_time = between(0.1, 0.5)  # Very short wait time
              
              def on_start(self):
                  """Called when a user starts"""
                  self.login()
              
              def login(self):
                  """Simulate user login"""
                  response = self.client.post("/api/auth/login/", json={
                      "username": "testuser",
                      "password": "testpass"
                  })
                  if response.status_code == 200:
                      self.token = response.json().get("token")
                      self.client.headers.update({"Authorization": f"Token {self.token}"})
              
              @task(5)
              def high_frequency_requests(self):
                  """High frequency API requests"""
                  self.client.get("/api/")
              
              @task(3)
              def database_intensive_operations(self):
                  """Database intensive operations"""
                  self.client.get("/api/workspaces/")
                  self.client.get("/api/campaigns/")
              
              @task(2)
              def complex_queries(self):
                  """Complex database queries"""
                  self.client.get("/api/campaigns/?search=test&ordering=-created_at")
              
              @task(1)
              def file_operations(self):
                  """File upload operations"""
                  files = {"file": ("test.txt", "test content", "text/plain")}
                  self.client.post("/api/workspaces/1/upload/", files=files)
          EOF

      - name: Run stress test
        run: |
          echo "Starting stress testing..."
          
          # Run stress test with high user count
          locust -f stress_test.py --headless -u 200 -r 10 -t 600s --html stress_test_report.html || true

      - name: Upload stress test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: stress-test-report
          path: stress_test_report.html

  # Endurance testing
  endurance-testing:
    name: Endurance Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'endurance' || github.event_name == 'schedule'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install performance testing tools
        run: |
          pip install locust
          pip install requests

      - name: Create endurance test script
        run: |
          cat > endurance_test.py << 'EOF'
          from locust import HttpUser, task, between
          import random
          import time
          
          class EnduranceTestUser(HttpUser):
              wait_time = between(2, 5)  # Normal wait time
              
              def on_start(self):
                  """Called when a user starts"""
                  self.login()
              
              def login(self):
                  """Simulate user login"""
                  response = self.client.post("/api/auth/login/", json={
                      "username": "testuser",
                      "password": "testpass"
                  })
                  if response.status_code == 200:
                      self.token = response.json().get("token")
                      self.client.headers.update({"Authorization": f"Token {self.token}"})
              
              @task(3)
              def normal_usage_pattern(self):
                  """Normal usage pattern"""
                  self.client.get("/")
                  self.client.get("/api/")
                  self.client.get("/api/workspaces/")
              
              @task(2)
              def campaign_management(self):
                  """Campaign management operations"""
                  self.client.get("/api/campaigns/")
                  self.client.post("/api/campaigns/", json={
                      "name": f"Endurance Campaign {random.randint(1, 1000)}",
                      "description": "Endurance test campaign",
                      "budget": 1000.00,
                      "start_date": "2024-01-01T00:00:00Z",
                      "end_date": "2024-12-31T23:59:59Z"
                  })
              
              @task(1)
              def asset_operations(self):
                  """Asset operations"""
                  self.client.get("/api/workspaces/1/assets/")
                  files = {"file": ("test.txt", "test content", "text/plain")}
                  self.client.post("/api/workspaces/1/upload/", files=files)
          EOF

      - name: Run endurance test
        run: |
          echo "Starting endurance testing..."
          
          # Run endurance test for extended period
          locust -f endurance_test.py --headless -u 100 -r 2 -t 1800s --html endurance_test_report.html || true

      - name: Upload endurance test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: endurance-test-report
          path: endurance_test_report.html

  # Spike testing
  spike-testing:
    name: Spike Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'spike' || github.event_name == 'schedule'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install performance testing tools
        run: |
          pip install locust
          pip install requests

      - name: Create spike test script
        run: |
          cat > spike_test.py << 'EOF'
          from locust import HttpUser, task, between
          import random
          
          class SpikeTestUser(HttpUser):
              wait_time = between(0.5, 2)  # Short wait time for spikes
              
              def on_start(self):
                  """Called when a user starts"""
                  self.login()
              
              def login(self):
                  """Simulate user login"""
                  response = self.client.post("/api/auth/login/", json={
                      "username": "testuser",
                      "password": "testpass"
                  })
                  if response.status_code == 200:
                      self.token = response.json().get("token")
                      self.client.headers.update({"Authorization": f"Token {self.token}"})
              
              @task(5)
              def rapid_requests(self):
                  """Rapid API requests"""
                  self.client.get("/api/")
              
              @task(3)
              def concurrent_operations(self):
                  """Concurrent operations"""
                  self.client.get("/api/workspaces/")
                  self.client.get("/api/campaigns/")
              
              @task(2)
              def simultaneous_uploads(self):
                  """Simultaneous file uploads"""
                  files = {"file": ("test.txt", "test content", "text/plain")}
                  self.client.post("/api/workspaces/1/upload/", files=files)
          EOF

      - name: Run spike test
        run: |
          echo "Starting spike testing..."
          
          # Run spike test with sudden user increase
          locust -f spike_test.py --headless -u 500 -r 50 -t 300s --html spike_test_report.html || true

      - name: Upload spike test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: spike-test-report
          path: spike_test_report.html

  # Performance monitoring
  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install monitoring tools
        run: |
          pip install requests
          pip install psutil

      - name: Create performance monitoring script
        run: |
          cat > performance_monitor.py << 'EOF'
          import requests
          import time
          import json
          from datetime import datetime
          
          def monitor_endpoint(url, name):
              """Monitor a specific endpoint"""
              start_time = time.time()
              try:
                  response = requests.get(url, timeout=30)
                  end_time = time.time()
                  response_time = end_time - start_time
                  
                  return {
                      "endpoint": name,
                      "url": url,
                      "status_code": response.status_code,
                      "response_time": response_time,
                      "timestamp": datetime.now().isoformat(),
                      "success": response.status_code == 200
                  }
              except Exception as e:
                  return {
                      "endpoint": name,
                      "url": url,
                      "status_code": None,
                      "response_time": None,
                      "timestamp": datetime.now().isoformat(),
                      "success": False,
                      "error": str(e)
                  }
          
          def main():
              # Monitor production endpoints
              endpoints = [
                  ("https://your-domain.com/", "Homepage"),
                  ("https://your-domain.com/api/", "API Root"),
                  ("https://your-domain.com/api/workspaces/", "Workspaces API"),
                  ("https://your-domain.com/api/campaigns/", "Campaigns API"),
                  ("https://your-domain.com/health/", "Health Check")
              ]
              
              results = []
              for url, name in endpoints:
                  result = monitor_endpoint(url, name)
                  results.append(result)
                  print(f"{name}: {result['response_time']:.2f}s" if result['success'] else f"{name}: FAILED")
              
              # Save results to file
              with open('performance_monitor_results.json', 'w') as f:
                  json.dump(results, f, indent=2)
              
              # Check for performance issues
              slow_endpoints = [r for r in results if r['success'] and r['response_time'] and r['response_time'] > 5.0]
              if slow_endpoints:
                  print(f"⚠️ {len(slow_endpoints)} endpoints are slow (>5s)")
                  for endpoint in slow_endpoints:
                      print(f"  - {endpoint['endpoint']}: {endpoint['response_time']:.2f}s")
              else:
                  print("✅ All endpoints are performing well")
          
          if __name__ == "__main__":
              main()
          EOF

      - name: Run performance monitoring
        run: |
          python performance_monitor.py

      - name: Upload performance monitoring results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-monitoring-results
          path: performance_monitor_results.json

  # Performance summary
  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [load-testing, stress-testing, endurance-testing, spike-testing, performance-monitoring]
    if: always()
    steps:
      - name: Performance summary
        run: |
          echo "Performance Testing Summary:"
          echo "==========================="
          echo "Load Testing: ${{ needs.load-testing.result }}"
          echo "Stress Testing: ${{ needs.stress-testing.result }}"
          echo "Endurance Testing: ${{ needs.endurance-testing.result }}"
          echo "Spike Testing: ${{ needs.spike-testing.result }}"
          echo "Performance Monitoring: ${{ needs.performance-monitoring.result }}"
          
          # Check overall performance
          if [ "${{ needs.load-testing.result }}" == "success" ] && 
             [ "${{ needs.stress-testing.result }}" == "success" ] && 
             [ "${{ needs.endurance-testing.result }}" == "success" ] && 
             [ "${{ needs.spike-testing.result }}" == "success" ] && 
             [ "${{ needs.performance-monitoring.result }}" == "success" ]; then
            echo "✅ All performance tests passed"
          else
            echo "⚠️ Some performance tests failed"
          fi

      - name: Notify performance status
        if: always()
        run: |
          if [ "${{ needs.performance-summary.result }}" == "success" ]; then
            echo "✅ Performance tests passed"
            # Send success notification
            curl -X POST -H 'Content-type: application/json' \
              --data '{"text":"✅ Performance tests passed for commit ${{ github.sha }}"}' \
              ${{ secrets.SLACK_WEBHOOK_URL }} || true
          else
            echo "❌ Performance tests failed"
            # Send failure notification
            curl -X POST -H 'Content-type: application/json' \
              --data '{"text":"❌ Performance tests failed for commit ${{ github.sha }}"}' \
              ${{ secrets.SLACK_WEBHOOK_URL }} || true
          fi
